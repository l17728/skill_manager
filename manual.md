# SkillManager 用户手册

**版本 2.0 · 适用平台：Windows 10 / Windows 11**

> 本手册面向**完全没有接触过本软件**的新用户，无需阅读其他文档，按照本手册即可完成安装、配置并独立使用所有功能。

---

## 目录

1. [产品简介——SkillManager 是什么](#1-产品简介skillmanager-是什么)
2. [核心概念一分钟速懂](#2-核心概念一分钟速懂)
3. [安装前的准备工作](#3-安装前的准备工作)
4. [安装 SkillManager（四步完成）](#4-安装-skillmanager四步完成)
5. [首次启动与界面认识](#5-首次启动与界面认识)
6. [10 分钟快速上手（建议新手先看这里）](#6-10-分钟快速上手建议新手先看这里)
7. [Skills & Agents 管理——详细指南](#7-skills--agents-管理详细指南)
8. [测试基线（Baselines）管理——详细指南](#8-测试基线baselines管理详细指南)
9. [测试项目（Projects）管理——详细指南](#9-测试项目projects管理详细指南)
10. [自动化对比测试](#10-自动化对比测试)
11. [差异分析与优势识别](#11-差异分析与优势识别)
12. [Skill 优势重组](#12-skill-优势重组)
13. [迭代验证闭环](#13-迭代验证闭环)
14. [Rankings 成绩排行榜](#14-rankings-成绩排行榜)
15. [数据管理与备份](#15-数据管理与备份)
16. [常见问题与解决方法](#16-常见问题与解决方法)

---

## 1. 产品简介——SkillManager 是什么

**SkillManager** 是一款本地桌面应用，帮助 AI 提示词工程师和 Agent 开发者完成以下工作：

| 你想做的事 | SkillManager 怎么帮 |
|-----------|-------------------|
| 管理多个提示词版本 | 统一存档，自动版本控制，随时回滚 |
| 比较哪个提示词更好 | 用同一批测试题自动打分，100 分制量化对比 |
| 找出好在哪里 | AI 自动分析差异，提取各自优势片段 |
| 生成更强的提示词 | 自动融合多个提示词的最优部分 |
| 持续打磨到满意 | 自动循环"优化→测试→分析"，直到达到目标分数 |
| 查看历史成绩 | 排行榜展示所有提示词的测试记录和新鲜度 |

**所有数据保存在本地**，无需数据库，无需云服务，断网也能使用（执行测试时需要联网）。

---

## 2. 核心概念一分钟速懂

在开始之前，先理解三个最重要的概念：

### Skill（技能/提示词）
一段你写给 Claude 的指令文本，用于让 Claude 完成某项特定任务。

**例子**：
```
你是一位专业的 Python 开发工程师。当用户提出编程需求时，
请编写符合 PEP8 规范的 Python 代码，包含必要的异常处理和注释。
代码需要简洁高效，避免不必要的复杂度。
```

### Baseline（测试基线）
一组"标准考题"，每道题有输入（题目）和预期输出（参考答案）。用同一套考题考不同的 Skill，谁答得更接近参考答案，谁的分就更高。

**例子**：
```
题目（输入）：写一个 Python 函数，输入一个列表，返回其中所有偶数
预期输出（参考）：def get_even_numbers(lst): return [x for x in lst if x % 2 == 0]
```

### Project（测试项目）
把"哪些 Skill"和"哪套考题"绑定在一起，执行一次完整测试实验。

**三者关系**：
```
Project（项目）
  ├── Skill A ──┐
  ├── Skill B ──┼── 都用同一套 Baseline 测试 → 得到各自分数 → 排名对比
  └── Skill C ──┘
```

---

## 3. 安装前的准备工作

### 3.1 如何打开命令提示符（CMD）

本手册后续步骤需要在"命令提示符"中输入命令。打开方式：

**方式 A**（最简单）：按键盘 `Win + R`，在弹出的框中输入 `cmd`，按回车。

**方式 B**：点击屏幕左下角"开始"按钮，搜索"命令提示符"，点击打开。

> **重要**：安装 Node.js 或其他软件后，必须**关闭并重新打开**命令提示符，新安装的程序才能被找到。

---

### 3.2 注册 Anthropic 账户

SkillManager 的测试、分析、打标签等功能需要调用 Claude AI，必须有 Anthropic 账户。

1. 访问 [https://console.anthropic.com](https://console.anthropic.com)
2. 点击 **Sign Up** 注册账户（可用邮箱或 Google 账号）
3. 完成邮箱验证
4. 账户注册完成后，后续安装 Claude Code CLI 时会用到

> 如果你已经有 Claude.ai 的账户，可以直接使用同一个账户登录。

---

### 3.3 系统要求检查

| 项目 | 要求 | 说明 |
|------|------|------|
| 操作系统 | Windows 10 / Windows 11（64 位） | 其他系统暂不支持 |
| 磁盘空间 | ≥ 500 MB | 用于存放程序和依赖库 |
| 网络 | 首次安装需要联网 | 后续管理资产无需联网，执行测试需联网 |

---

## 4. 安装 SkillManager（四步完成）

### 第一步：安装 Node.js

Node.js 是运行 SkillManager 所必需的 JavaScript 运行环境。

1. 打开浏览器，访问 [https://nodejs.org/zh-cn](https://nodejs.org/zh-cn)
2. 点击 **"LTS 推荐大多数用户使用"** 版本按钮，下载 `.msi` 安装文件
3. 双击下载的文件，一路点击"下一步"，保持**所有默认选项**（特别注意不要取消勾选"Add to PATH"）
4. 安装完成后，**关闭并重新打开**命令提示符
5. 输入以下两条命令验证安装（每行一条，按回车执行）：

```
node --version
npm --version
```

看到类似 `v20.11.0` 和 `10.2.4` 这样的版本号，表示安装成功。

---

### 第二步：安装 Git（用于下载 SkillManager 代码）

1. 访问 [https://git-scm.com/download/win](https://git-scm.com/download/win)，下载安装包
2. 运行安装包，保持所有默认选项，一路点击"Next"直到完成
3. **关闭并重新打开**命令提示符

---

### 第三步：安装 Claude Code CLI

Claude Code CLI 是 SkillManager 与 Claude AI 交互的"桥梁"，所有 AI 功能（测试评分、自动打标签、差异分析）都通过它完成。

在命令提示符中输入：

```
npm install -g @anthropic-ai/claude-code
```

等待安装完成（需要 1-3 分钟），然后验证：

```
claude --version
```

看到版本号表示安装成功。

**完成 Anthropic 账户授权**（必须完成，否则 AI 功能无法使用）：

```
claude auth login
```

运行后会弹出浏览器，在网页上确认授权即可。授权成功后命令提示符会显示确认信息。

> **提示**：没有完成授权时，资产管理功能（导入/编辑 Skill）仍可正常使用，但 AI 相关功能（测试、分析、打标签）无法执行，顶部状态灯显示红色。

---

### 第四步：下载 SkillManager 并安装依赖

在命令提示符中，依次执行以下命令（每行按回车执行一次）：

```
git clone https://github.com/l17728/skill_manager.git
cd skill_manager
npm install
```

- `git clone`：把代码下载到当前目录下的 `skill_manager` 文件夹
- `cd skill_manager`：进入该文件夹
- `npm install`：自动安装所有依赖库（需要 2-5 分钟，下载约 300-400 MB）

看到如下信息表示安装完成：

```
added xxx packages in xxxs
```

**启动应用**：

```
npm run dev
```

几秒后弹出应用窗口，安装完成！

> **关于启动时的警告信息**：启动后命令提示符中可能出现 `Can't find filter element` 字样，**这是正常现象**，是 Electron 框架的内部日志，不影响任何功能，直接忽略即可。

---

### 打包为独立安装包（可选，方便分发）

如果需要把应用打包为 `.exe` 安装文件分发给他人：

```
npm run build
```

打包完成后，`dist/` 目录下的 `.exe` 文件可以直接在其他 Windows 电脑上安装（目标电脑仍需完成第三步 Claude Code CLI 的安装和授权）。

---

## 5. 首次启动与界面认识

运行 `npm run dev` 后，应用窗口弹出，整体界面如下：

```
┌──────────────────────────────────────────────────────────────────┐
│  ⚡ SkillManager  [ Skills & Agents ] [ Baselines ] [ Projects ]  │
│                   [ Rankings ]                    ● CLI: v1.x.x  │
├────────────────────────────────────────────────────────────────—─┤
│ 左侧：列表面板           │ 右侧：详情/操作面板                    │
│ （搜索、筛选、条目列表）  │ （选中条目的详情、编辑区、操作按钮）   │
└──────────────────────────────────────────────────────────────────┘
```

### 顶部导航说明

| 导航项 | 作用 |
|--------|------|
| **Skills & Agents** | 管理所有提示词和 Agent（默认打开此页） |
| **Baselines** | 管理测试基线（测试用例集合） |
| **Projects** | 创建测试项目、查看测试结果、执行分析重组 |
| **Rankings** | 查看所有 Skill 的历史成绩排行榜 |

### CLI 状态指示灯（右上角）

| 颜色 | 含义 |
|------|------|
| 🟢 绿色（online） | Claude Code CLI 正常，AI 功能可用 |
| 🔴 红色（offline） | CLI 不可用，请检查安装或授权 |

> **刚启动时显示红色是正常的**，等待 2-3 秒后会自动检测并更新状态。

---

## 6. 10 分钟快速上手（建议新手先看这里）

跟着下面的步骤操作一遍，你就能掌握 SkillManager 的核心工作流程。

**目标**：导入两个写 Python 代码的提示词，创建一套测试题，测试并比较它们的表现。

---

### 步骤 1：导入第一个 Skill（2 分钟）

1. 点击顶部 **Skills & Agents**
2. 点击左侧面板右上角的 **+ Import** 按钮
3. 在弹窗中填写：
   - **Name**：`Python助手-简洁版`
   - **Content**（粘贴以下内容）：
     ```
     你是一位 Python 编程助手。请根据用户的需求，用最简洁的方式写出 Python 代码，不要添加多余的注释。
     ```
   - **Purpose**：`coding`
   - **Provider**：`internal`
4. 点击 **Confirm Import**

左侧列表出现刚导入的 Skill，表示成功。

---

### 步骤 2：导入第二个 Skill（1 分钟）

重复步骤 1，但 Content 改为：

```
你是一位资深 Python 开发工程师，擅长编写高质量、可维护的代码。
请根据用户需求，编写符合 PEP8 规范的 Python 代码，包含：
1. 完整的异常处理
2. 必要的代码注释
3. 清晰的变量命名
```

**Name** 填 `Python助手-专业版`，其余字段相同。

---

### 步骤 3：创建测试基线（2 分钟）

1. 点击顶部 **Baselines**
2. 点击 **+ Import**
3. 填写：
   - **Name**：`Python基础测试`
   - **Purpose**：`coding`
   - **Provider**：`internal`
4. 在用例区域点击 **+ Add Case**，添加一条测试用例：
   - **用例名称**：`求偶数列表`
   - **输入**：`写一个Python函数，输入一个整数列表，返回其中所有偶数`
   - **预期输出**：`def get_evens(lst): return [x for x in lst if x % 2 == 0]`
5. 再添加一条：
   - **用例名称**：`字符串反转`
   - **输入**：`写一个Python函数，输入一个字符串，返回其反转结果`
   - **预期输出**：`def reverse_string(s): return s[::-1]`
6. 点击 **Confirm Import**

---

### 步骤 4：创建测试项目（1 分钟）

1. 点击顶部 **Projects**
2. 点击 **+ Create Project**
3. 填写：
   - **Project Name**：`Python助手对比实验`
   - **Skills**：勾选 `Python助手-简洁版` 和 `Python助手-专业版`
   - **Baselines**：勾选 `Python基础测试`
4. 点击 **Create**

---

### 步骤 5：执行测试（约 2-5 分钟）

> ⚠️ 需要 CLI 状态为绿色（在线）。

1. 点击左侧刚创建的项目，右侧显示项目详情
2. 点击 **Test** 标签页
3. 点击 **▶ Start Test**
4. 等待测试完成（进度条走满，状态变为"已完成"）

---

### 步骤 6：查看结果

测试完成后，Test 页面显示两个 Skill 的得分排名：

```
# 排名    Skill名称          平均分
1         Python助手-专业版   82
2         Python助手-简洁版   71
```

点击某行展开，可以看到功能正确性、健壮性等 6 个维度的详细得分。

**恭喜！** 你已经完成了一次完整的对比测试。接下来可以探索分析、重组和迭代功能（详见后续章节）。

---

## 7. Skills & Agents 管理——详细指南

### 7.1 导入 Skill

1. 点击顶部 **Skills & Agents**
2. 点击 **+ Import** 按钮
3. 在弹窗中填写字段：

| 字段 | 说明 | 是否必填 | 示例 |
|------|------|---------|------|
| **Name** | Skill 的显示名称 | ✅ 必填 | `Python代码助手v2` |
| **Content** | 粘贴提示词全文 | ✅ 必填 | 见下方说明 |
| **Purpose** | 用途分类（可自定义） | ✅ 必填 | `coding` / `writing` / `analysis` |
| **Provider** | 来源标识（可自定义） | ✅ 必填 | `anthropic` / `openai` / `internal` |
| **Type** | 类型 | 可选 | `skill`（提示词）/ `agent`（智能体） |
| **Description** | 功能简介 | 可选 | `专注Python代码生成，强调PEP8规范` |
| **Author** | 创建者 | 可选 | 你的名字 |

> **关于 Purpose 和 Provider**：这两个字段是**自定义分类标签**，你可以填任意英文字符串。用于将 Skill 分层归档，便于管理。例如：Purpose 填 `coding` 表示这是用于写代码的 Skill；Provider 填 `internal` 表示是你自己写的。

> **Content 填什么？** 就是你平时给 Claude 写的"系统提示词"（System Prompt）全文。如果你还没有，可以用第 6 章的示例练习。

4. 点击 **Confirm Import**，左侧列表出现新条目表示成功。

---

### 7.2 浏览与搜索

左侧列表支持多种过滤方式，所有过滤条件可叠加使用：

| 过滤方式 | 操作 |
|---------|------|
| 按名称/描述搜索 | 在顶部搜索框输入关键词，实时过滤 |
| 按标签筛选 | 在 Tag 过滤框输入标签，按回车添加，可叠加多个 |
| 按用途筛选 | 在 Purpose 输入框输入 `coding` 等关键词 |
| 按来源筛选 | 在 Provider 输入框输入关键词 |
| 翻页 | 点击列表底部 `< >` 按钮 |

**Hover 预览**：鼠标悬停在列表中的某个 Skill 上，会弹出包含提示词核心内容的预览卡片，无需点击进入详情页即可快速浏览。

**成绩 Badge**：有测试记录的 Skill 右侧会出现彩色分数标识（如 `✓ 85`）：
- 绿色 `✓`：当前版本有效成绩
- 黄色 `⚠`：Skill 已更新，成绩对应旧版本
- 灰色 `◆`：基线已更新，参照标准已变

点击 Badge 可跳转到 Rankings 页并自动以该 Skill 过滤。

---

### 7.3 查看 Skill 详情

**点击列表中的某个 Skill**，右侧面板展开详情，显示：
- 完整提示词内容
- 元数据（名称、版本号、用途、来源、类型等）
- 标签（手动标签 + 已审核的自动标签）
- 版本历史

---

### 7.4 编辑 Skill

1. 在左侧列表点击选中某个 Skill
2. 在右侧详情面板顶部，点击 **Edit** 按钮（面板右上角区域）
3. 在弹窗中修改提示词内容或元数据
4. 点击 **Save**

> **版本自动递增**：每次保存都会生成新版本（v1 → v2 → v3…），系统记录修改前后的差异（diff），随时可以查看或回滚。

---

### 7.5 版本历史与回滚

在详情面板中，向下滚动找到 **History（版本历史）** 区域：

- 列出所有历史版本（v1、v2、v3…）及修改时间
- 点击某个版本可查看该版本内容
- 点击版本右侧的 **Rollback** 按钮回滚

> **回滚原理**：回滚不会覆盖现有版本，而是将旧版本内容**复制为一个新版本**（v3 回滚后变成 v4）。历史记录永久保留。

---

### 7.6 标签管理

**手动添加标签**：
1. 在详情面板中找到标签区域
2. 点击 **+ Add Tag** 按钮
3. 输入标签文字（如 `python`、`代码生成`），按回车确认
4. 点击标签旁的 **×** 删除标签

**自动打标签**（需要 CLI 在线）：
1. 选中某个 Skill
2. 在详情面板右上角找到 **Auto Tag** 按钮，点击
3. 弹窗确认后，系统后台调用 Claude CLI 分析内容（约 30-60 秒）
4. 完成后，新生成的标签显示为**"待审核"**状态
5. 在详情面板的自动标签区域，对每个候选标签操作：
   - 点击 **✓（勾选）** → 标签生效，加入实际标签列表
   - 点击 **×（拒绝）** → 丢弃该候选标签
6. 审核通过的标签会参与搜索过滤

---

### 7.7 删除（归档）Skill

1. 选中某个 Skill
2. 在详情面板右上角点击 **Archive** 按钮
3. 在确认弹窗中点击确认

> **什么是归档？** 归档后 Skill 从列表中消失，但文件**仍保留在磁盘**（`workspace/skills/` 目录下），不会物理删除，必要时可手动恢复。

---

## 8. 测试基线（Baselines）管理——详细指南

> **什么是测试基线？** 基线就是一套"标准化试卷"。每道题（用例）包含：题目（输入）和参考答案（预期输出）。用同一套试卷考不同的 Skill，得分越高说明越接近参考答案。

### 8.1 导入基线

1. 点击顶部 **Baselines**
2. 点击 **+ Import**
3. 在弹窗中先填写基本信息：

| 字段 | 说明 | 示例 |
|------|------|------|
| **Name** | 基线名称 | `Python编程基础测试` |
| **Purpose** | 测试目的（与 Skill 的 Purpose 对应） | `coding` |
| **Provider** | 来源标识 | `internal` |

4. 选择添加用例的方式：

**方式 A：手动逐条录入**（推荐新手）

点击 **+ Add Case**，逐条填写：

| 字段 | 说明 | 示例 |
|------|------|------|
| **用例名称** | 这道题的名字 | `求列表中的偶数` |
| **输入** | 给 Claude 的问题/指令 | `写一个Python函数，输入整数列表，返回其中所有偶数` |
| **预期输出** | 期望的正确答案 | `def get_evens(lst): return [x for x in lst if x % 2 == 0]` |

> **预期输出写什么？** 写你认为理想的正确答案。Claude 会根据你的预期输出来评分——越接近预期，分越高。预期输出不需要完全精确，写出关键要素即可。

**方式 B：JSON 文件导入**

准备一个 `.json` 文件，格式如下：

```json
[
  {
    "name": "求列表中的偶数",
    "input": "写一个Python函数，输入整数列表，返回其中所有偶数",
    "expected_output": "def get_evens(lst): return [x for x in lst if x % 2 == 0]"
  },
  {
    "name": "字符串反转",
    "input": "写一个Python函数，输入字符串，返回其反转结果",
    "expected_output": "def reverse_string(s): return s[::-1]"
  }
]
```

点击上传区域选择文件。

5. 点击 **Confirm Import**

---

### 8.2 浏览与管理基线

与 Skills 页面布局完全一致：左侧列表，右侧详情。

详情面板包含：
- 基线基本信息（名称、用途、来源、版本、用例数量）
- 所有测试用例列表（可展开查看每条用例详情）
- 标签管理区域（操作与 Skill 标签完全一致）
- 版本历史

---

### 8.3 管理测试用例

在基线详情面板中：

- 点击 **+ Add Case**：新增用例
- 点击用例条目右侧的 ✏️ **编辑图标**：修改该用例的内容
- 点击 🗑️ **删除图标**：删除该用例

> 修改用例后系统会自动生成新版本，旧版本用例记录永久保留，可通过版本历史回滚。

---

## 9. 测试项目（Projects）管理——详细指南

> **什么是测试项目？** 项目是一次完整的对比测试实验。你指定"哪些 Skill"和"哪套测试基线"，系统自动执行所有组合并记录结果。

### 9.1 创建项目

1. 点击顶部 **Projects**
2. 点击 **+ Create Project**
3. 在弹窗中填写：

| 字段 | 说明 | 注意 |
|------|------|------|
| **Project Name** | 项目名称 | 如 `Python助手对比-2024` |
| **Skills** | 勾选参与测试的 Skill | 至少选 1 个，可选多个 |
| **Baselines** | 勾选测试基线 | 至少选 1 个 |

4. 点击 **Create**

系统自动完成：
- 生成独立项目目录（测试期间原 Skill/Baseline 修改不影响项目）
- 创建 Claude 独立会话目录

---

### 9.2 项目状态说明

| 状态 | 含义 |
|------|------|
| **未开始** | 项目已创建，测试尚未启动 |
| **运行中** | 测试正在执行 |
| **已完成** | 所有用例测试完毕，结果已归档 |
| **中断** | 测试中途被暂停或异常中断，可恢复 |

---

### 9.3 进入项目详情

**点击左侧列表中的项目名称**，右侧面板展开详情，包含 5 个标签页：

| 标签 | 什么时候用 | 功能说明 |
|------|-----------|---------|
| **Overview** | 随时 | 查看项目配置（关联的 Skill、基线列表等） |
| **Test** | 第一步 | 启动测试、监控进度、查看测试结果 |
| **Analysis** | 测试完成后 | 运行 AI 差异分析，查看各 Skill 优劣 |
| **Recompose** | 分析完成后 | 自动融合各 Skill 优势，生成新版本 |
| **Iteration** | 随时 | 配置并运行自动迭代优化闭环 |

> **操作顺序非常重要**：必须先 Test → 再 Analysis → 再 Recompose，跳步会报错。

---

### 9.4 搜索与删除项目

- **搜索**：左侧列表顶部输入框，按项目名称过滤
- **删除**：选中项目 → 详情面板右上角 **Delete** 按钮 → 确认

> ⚠️ 删除项目**不可恢复**，项目下所有测试结果和分析报告将一同删除。

---

## 10. 自动化对比测试

> 在 **Projects** → 项目详情 → **Test** 标签页中执行。

### 10.1 开始测试

> ⚠️ **前提**：顶部 CLI 状态为绿色（在线），否则无法执行测试。

1. 点击左侧选中某个项目
2. 点击右侧详情面板的 **Test** 标签
3. 点击 **▶ Start Test**
4. 系统开始对每个 Skill 执行基线中的所有用例（Skill 之间并行，每个 Skill 内的用例顺序执行）

**测试过程中可以看到**：
- 进度条：已完成用例数 / 总用例数
- 实时状态：每条用例的执行状态（运行中 / 成功 / 失败）

**测试时间估算**：
- 每条用例约 15-30 秒（网络和 API 速度影响）
- 2 个 Skill × 5 条用例 = 约 2-5 分钟
- 5 个 Skill × 10 条用例 = 约 12-25 分钟

---

### 10.2 暂停与恢复

| 按钮 | 作用 |
|------|------|
| **⏸ Pause** | 暂停（已完成的用例结果保留） |
| **▶ Resume** | 从暂停处继续（不重复执行已完成的用例） |
| **⏹ Stop** | 终止测试（已完成的结果保留，可查看部分结果） |

---

### 10.3 查看测试结果

测试完成后，Test 页面显示排名和得分：

**排名表格**：
```
排名  Skill 名称           平均分   用例
1     Python助手-专业版    82       5/5
2     Python助手-简洁版    71       5/5
```

**6 维度得分**（点击某行展开）：

| 维度 | 满分 | 评判要点 |
|------|------|---------|
| 功能正确性 | 30 分 | 代码是否准确实现需求，核心逻辑是否正确 |
| 健壮性 | 20 分 | 异常处理是否完善，边界条件是否覆盖 |
| 代码可读性 | 15 分 | 命名规范、结构清晰、注释适当 |
| 代码简洁性 | 15 分 | 无冗余代码、表达简洁高效 |
| 复杂度控制 | 10 分 | 避免不必要复杂度、模块合理拆分 |
| 格式规范性 | 10 分 | 符合语言规范与编码风格 |

**得分颜色含义**：
- 🟢 绿色：≥ 该维度满分的 80%（表现优秀）
- 🟡 黄色：≥ 60%（表现中等）
- 🔴 红色：< 60%（需要改进）

---

### 10.4 用例失败处理

某条用例失败（标记为 **Failed**）时，不影响其他用例继续执行，整体测试正常完成。

失败原因通常是：网络超时、API 限流、CLI 错误。查看详情：进入 `workspace/logs/` 目录，用记事本打开最新的 `.jsonl` 日志文件，找到对应的错误记录。

---

## 11. 差异分析与优势识别

> 在 **Projects** → 项目详情 → **Analysis** 标签页中执行。
>
> ⚠️ **前提**：该项目的测试状态为"已完成"，否则分析按钮不可用。

### 11.1 运行分析

1. 选中项目，点击 **Analysis** 标签
2. 点击 **▶ Run Analysis**
3. 系统调用 Claude CLI 分析各 Skill 的测试结果（约 30-60 秒）

---

### 11.2 分析报告内容

分析完成后，报告包含：

**① 最优 Skill 推荐**
- 综合得分最高的 Skill 及推荐理由（文字说明）

**② 各维度领先者**
- 每个评分维度（功能正确性、健壮性…）上表现最好的 Skill

**③ 优势片段提取**
- 从每个 Skill 中提取的关键片段，按类型分类展示：
  - **指令结构**：Skill 组织提示词的方式
  - **约束条件**：对输出格式/内容的限制
  - **输出格式**：如何要求 Claude 格式化输出
  - **角色设定**：如何定义 Claude 的角色
  - **示例内容**：Skill 中包含的 few-shot 示例

这些优势片段会在重组阶段作为素材使用。

---

### 11.3 导出分析报告

点击报告右上角 **Export Report** 按钮，报告以 JSON 格式保存到 `workspace/` 目录，并弹出成功通知（含文件路径）。

---

## 12. Skill 优势重组

> 在 **Projects** → 项目详情 → **Recompose** 标签页中执行。
>
> ⚠️ **前提**：该项目的分析已完成，否则重组按钮不可用。

重组功能将多个 Skill 的最优片段**自动融合**，生成一个新的更强 Skill。

### 12.1 执行重组

1. 选中项目，点击 **Recompose** 标签
2. 点击 **▶ Execute Recompose**
3. 系统调用 Claude CLI，根据分析报告的优势片段自动生成融合版本（约 30-60 秒）

重组完成后，预览区显示生成的新 Skill 完整内容。

---

### 12.2 编辑重组结果

系统生成的内容你可以自由修改：
- 直接在预览文本框中编辑任意内容
- 对不满意的部分进行润色

---

### 12.3 保存重组结果

1. 在保存区域填写新 Skill 的信息：
   - **Name**：如 `Python助手-融合版`
   - **Purpose** 和 **Provider**：与原来保持一致即可
2. 点击 **Save as New Skill**

保存后，新 Skill 自动出现在 Skills & Agents 列表中，并包含溯源信息（记录融合自哪些 Skill 的哪些片段）。

---

## 13. 迭代验证闭环

> 在 **Projects** → 项目详情 → **Iteration** 标签页中执行。

迭代是最强大的功能，它自动执行"重组 → 测试 → 分析 → 再重组"循环，持续优化 Skill 直到达到目标分数，无需人工干预。

### 13.1 配置迭代参数

| 参数 | 说明 | 推荐值 |
|------|------|--------|
| **Max Rounds（最大轮次）** | 最多迭代几轮，轮次越多耗时越长 | 3（初次使用） |
| **Stop Threshold（停止阈值）** | 平均分达到此值后自动停止 | 85 |
| **Mode（模式）** | 迭代策略（见下表） | Standard |

**三种迭代模式对比**：

| 模式 | 说明 | 每轮 API 调用量 | 适用场景 |
|------|------|---------------|---------|
| **Standard** | 每轮生成 1 个候选，标准推进 | 少 | 快速体验、资源有限时 |
| **Explore** | 每轮生成 2 个候选，选最优 | 中 | 想要探索更多可能性 |
| **Adaptive** | 智能检测分数停滞，自动切换激进策略 | 中-多 | 分数卡住、需要突破瓶颈时 |

---

### 13.2 启动迭代

点击 **▶ Start Iteration**，系统自动循环执行：

```
第 1 轮
  ├── 重组：AI 生成优化版 Skill
  ├── 测试：对优化版 Skill 跑全部基线用例
  └── 分析：计算得分，提取新优势

第 2 轮（基于第 1 轮的最优结果继续优化）
  ├── 重组 → 测试 → 分析
  ...

达到 Max Rounds 或 Stop Threshold 时自动结束
```

迭代过程中可以实时查看每轮的得分变化。

---

### 13.3 查看迭代报告

迭代完成后，报告包含：
- 每轮的 Skill 版本和得分
- 分数变化曲线（是否持续提升）
- 各轮使用的优化策略说明
- **最优版本推荐**（分数最高的那一轮）

点击 **Save Best Skill** 将最优版本保存为新 Skill。

---

### 13.4 暂停与停止

| 按钮 | 效果 |
|------|------|
| **⏸ Pause** | 当前轮执行完后暂停（不中断正在进行的轮次） |
| **⏹ Stop** | 立即终止（已完成的轮次结果保留，可查看） |

---

## 14. Rankings 成绩排行榜

> 点击顶部导航 **Rankings** 进入。
>
> **注意**：Rankings 页面的数据来自已完成测试的项目。如果你还没有跑过任何测试，页面会显示"暂无测试成绩记录"，这是正常的——完成第一次测试后数据会自动出现。

### 14.1 页面布局

```
┌──────────────────┬──────────────────────────────────────────┐
│   Rankings       │  ┌─ Python基础测试（基线名）────────────┐ │
│                  │  │ #   Skill名称        分数  用例  状态 │ │
│  🔍 搜索Skill名  │  │ 1   Python助手-专业版  82  5/5   ✓   │ │
│  [全部基线    ▼] │  │ 2   Python助手-简洁版  71  5/5   ✓   │ │
│  [全部用途    ▼] │  └──────────────────────────────────────┘ │
│  [全部时间    ▼] │                                          │
│  ☑ 包含过期成绩  │  ┌─ 另一条基线名────────────────────────┐ │
│                  │  │  ...                                  │ │
│  ── 视图 ──     │  └──────────────────────────────────────┘ │
│  [排名] [时间线] │                                          │
│                  │                                          │
│  [× 清除筛选]   │                                          │
│  [↓ 导出 CSV]   │                                          │
└──────────────────┴──────────────────────────────────────────┘
```

---

### 14.2 过滤条件详解

| 控件 | 功能 | 使用场景 |
|------|------|---------|
| 🔍 **搜索框** | 按 Skill 名称模糊搜索 | 快速定位某个 Skill |
| **全部基线** | 只看某条基线的成绩 | 专注对比某套测试题下的排名 |
| **全部用途** | 按 Purpose 过滤 | 只看 `coding` 类或 `writing` 类 |
| **全部时间** | 近 30 天 / 近 90 天 | 只看最近的测试记录 |
| **包含过期成绩** | 取消勾选后只显示"当前有效"的成绩 | 只想看最新有效数据时 |
| **× 清除筛选** | 重置所有过滤条件 | 回到全量视图 |

---

### 14.3 新鲜度状态——成绩是否还有效？

每条成绩记录右侧有一个**新鲜度图标**，表示这条成绩是否还有参考价值：

| 图标 | 含义 | 建议操作 |
|------|------|---------|
| **✓** 绿色 | 当前有效：Skill 和基线版本均未变，成绩完全有效 | 无需操作 |
| **⚠** 黄色 | Skill 已更新：测试后 Skill 有了新版本，成绩对应旧版本 | 重新测试 |
| **◆** 橙色 | 基线已更新：测试用例已修改，参照标准已变 | 重新测试 |
| **✕** 红色 | 全部已更新：Skill 和基线均已更新，成绩仅作历史参考 | 重新测试 |

> **实用建议**：勾选"包含过期成绩"可以看到历史记录（默认勾选）；取消勾选后只显示新鲜度为 ✓ 的成绩，排名更准确。

---

### 14.4 展开 6 维度详情

点击排名列表中的**任意一行**，该行展开显示 6 个维度的详细得分（功能正确性、健壮性、可读性等），便于深入了解 Skill 在哪些方面表现优秀，在哪些方面有改进空间。

---

### 14.5 时间线视图

1. 点击左侧 **时间线** 按钮切换视图
2. **必须先选择一条基线**（否则显示"请先选择基线"提示）
3. 图表展示：
   - X 轴 = 测试日期
   - Y 轴 = 平均分（0-100）
   - 每个 Skill 显示为一条折线
4. 可直观看到每次迭代后分数的提升轨迹

---

### 14.6 导出成绩 CSV

点击左侧 **↓ 导出 CSV** 按钮，将当前过滤条件下的所有记录导出为 CSV 文件：
- 文件自动保存到 `workspace/` 目录
- 弹出成功通知，通知中包含文件的完整路径
- 用 Excel 打开该文件即可进行进一步分析

---

## 15. 数据管理与备份

### 15.1 数据存储位置

所有数据保存在程序根目录的 `workspace/` 文件夹下，结构如下：

```
skill_manager/
└── workspace/
    ├── skills/        ← 所有 Skill 文件（按 purpose/provider 自动分层）
    ├── baselines/     ← 所有基线文件
    ├── projects/      ← 所有测试项目（含测试结果、分析报告）
    ├── cli/           ← CLI 配置和临时会话缓存
    └── logs/          ← 操作日志（每次启动生成一个新文件）
```

### 15.2 备份数据

**完整备份**：直接复制整个 `workspace/` 文件夹到其他位置：

```
# 打开命令提示符，进入程序目录后执行：
xcopy /E /I workspace "D:\我的备份\skillmanager_backup_20240601"
```

### 15.3 恢复数据

将备份的 `workspace/` 文件夹复制回程序根目录，**覆盖原有文件夹**，重启应用即可恢复。

### 15.4 查看操作日志

日志文件位于 `workspace/logs/`，以 `YYYY-MM-DD_HH-MM-SS.jsonl` 命名（如 `2024-06-01_14-30-00.jsonl`）。

用**记事本**打开日志文件，每行是一条 JSON 记录，包含操作类型、时间、成功/失败状态等信息，适合排查问题时查阅。

---

## 16. 常见问题与解决方法

### ❓ 问题 1：应用启动后窗口空白 / 闪退

**原因**：npm 依赖未正确安装。

**解决步骤**：
1. 打开命令提示符，进入程序目录：`cd skill_manager`
2. 执行：`npm install`
3. 等待完成后再执行：`npm run dev`

---

### ❓ 问题 2：顶部 CLI 状态一直是红色

**原因**：Claude Code CLI 未安装、未在 PATH 中，或未完成账户授权。

**解决步骤**：
1. 打开命令提示符，运行 `claude --version`
   - **如果报错"不是内部或外部命令"**：
     1. 执行 `npm install -g @anthropic-ai/claude-code`
     2. **关闭并重新打开**命令提示符
     3. 再次验证 `claude --version`
   - **如果能看到版本号但状态仍是红色**：
     1. 执行 `claude auth login`
     2. 在弹出的浏览器页面完成授权
     3. 重启应用
2. 如仍为红色，检查网络是否能访问 `console.anthropic.com`

---

### ❓ 问题 3：点击"Start Test"后长时间无响应或失败

**原因**：网络问题、API 配额耗尽，或 CLI 未授权。

**解决步骤**：
1. 确认 CLI 状态为绿色（在线）
2. 打开浏览器访问 `console.anthropic.com` 确认网络正常
3. 查看最新日志：打开 `workspace/logs/` 中最新的 `.jsonl` 文件，搜索 `error` 关键词找到错误原因

---

### ❓ 问题 4：自动打标签一直显示"进行中"

**原因**：CLI 调用需要 30-60 秒，属于正常等待时间。如果超过 3 分钟仍未完成，则为超时。

**解决步骤**：
1. 等待约 3 分钟
2. 如仍未完成，重启应用（按 `Ctrl + C` 终止，再执行 `npm run dev`）
3. 查看 `workspace/skills/.../.../auto_tag_log/` 目录下的日志文件了解失败原因

---

### ❓ 问题 5：Rankings 页面显示"暂无测试成绩记录"

**原因**：还没有完成过任何测试。Rankings 页面只显示已完成项目的成绩。

**解决步骤**：
1. 按照第 6 章"10 分钟快速上手"完成一次测试
2. 回到 Rankings 页面，数据会自动出现

---

### ❓ 问题 6：怎么"刷新"应用？

SkillManager 是桌面应用，没有浏览器的刷新按钮。如需刷新：

- **刷新当前页面内容**：点击顶部导航切换到其他页面，再切换回来
- **完全重启应用**：在命令提示符中按 `Ctrl + C` 终止，再执行 `npm run dev`

---

### ❓ 问题 7：Analysis 或 Recompose 按钮是灰色的，点不了

**原因**：操作有前置依赖，必须按顺序执行：

```
Test（完成测试）→ Analysis（运行分析）→ Recompose（执行重组）→ Iteration（迭代优化）
```

- Analysis 灰色 → 该项目测试尚未完成，先去 Test 标签完成测试
- Recompose 灰色 → 分析尚未运行，先去 Analysis 标签运行分析

---

### ❓ 问题 8：git clone 提示"不是内部或外部命令"

**原因**：Git 未安装。

**解决步骤**：
1. 访问 [https://git-scm.com/download/win](https://git-scm.com/download/win) 下载安装 Git
2. 安装完成后**重新打开**命令提示符
3. 再次执行 `git clone ...`

---

### ❓ 问题 9：需要重置所有数据

> ⚠️ **警告**：此操作删除所有 Skill、Baseline、Project 数据，**不可恢复**，请先备份。

在命令提示符中执行（确保已进入 skill_manager 目录）：

```
rmdir /S /Q workspace
```

重启应用后，`workspace/` 会自动重新创建为空状态。

---

## 附录：完整使用示例（带真实提示词内容）

以下是一个可以直接复制操作的完整示例，从零开始比较两个 Python 提示词并生成优化版本。

---

### 准备两个 Skill

**Skill 1 — Python助手（简洁版）**

Name: `Python助手-简洁版`
Purpose: `coding`
Provider: `internal`
Content（完整复制以下内容）:
```
你是一位 Python 编程助手。请根据用户的需求，用最简洁的方式写出 Python 代码，不要添加多余的注释。
```

---

**Skill 2 — Python助手（专业版）**

Name: `Python助手-专业版`
Purpose: `coding`
Provider: `internal`
Content（完整复制以下内容）:
```
你是一位资深 Python 开发工程师，擅长编写高质量、可维护的 Python 代码。

当用户提出编程需求时，请遵循以下原则：
1. 代码符合 PEP8 规范
2. 包含完整的异常处理（try/except）
3. 关键步骤添加简洁注释
4. 使用清晰的变量命名
5. 避免不必要的复杂度

请直接输出可运行的代码，不需要额外解释。
```

---

### 准备一套测试基线

Name: `Python基础5题`
Purpose: `coding`
Provider: `internal`

用例列表（逐条添加）：

| 用例名称 | 输入 | 预期输出 |
|---------|------|---------|
| 求偶数 | 写一个Python函数，输入整数列表，返回其中所有偶数 | `def get_evens(lst): return [x for x in lst if x % 2 == 0]` |
| 字符串反转 | 写一个Python函数，输入字符串，返回反转结果 | `def reverse_string(s): return s[::-1]` |
| 列表去重 | 写一个Python函数，输入列表，返回去重后保持顺序的列表 | `def deduplicate(lst): seen = set(); return [x for x in lst if not (x in seen or seen.add(x))]` |
| 统计字符频率 | 写一个Python函数，统计字符串中每个字符出现的次数，返回字典 | `def char_freq(s): freq = {}; [freq.update({c: freq.get(c, 0) + 1}) for c in s]; return freq` |
| 斐波那契数列 | 写一个Python函数，输入n，返回前n个斐波那契数的列表 | `def fibonacci(n): a, b, result = 0, 1, []; [result.append(a) or (a, b).__setitem__(0, b) for _ in range(n)]; return result` |

---

### 操作步骤

1. **导入两个 Skill**（按照上面的内容）
2. **创建基线**，添加 5 条用例
3. **创建项目**：选择两个 Skill + 这套基线
4. **Test 标签** → **Start Test** → 等待完成
5. **Analysis 标签** → **Run Analysis** → 查看报告
6. **Recompose 标签** → **Execute Recompose** → 保存为 `Python助手-融合版`
7. **Rankings 页面** → 查看三个 Skill 的历史成绩对比

---

*文档版本：2.0 · 最后更新：2026-02-28*
